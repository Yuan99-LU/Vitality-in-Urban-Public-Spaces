{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import pyLDAvis.gensim\n",
    "import numpy as np\n",
    "from datetime import datetime, date, time\n",
    "import csv\n",
    "import sys\n",
    "import importlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_vctorize(n_max_features, text):\n",
    "    #n_features = 1000\n",
    "    tf_vectorizer = CountVectorizer(strip_accents = 'unicode',\n",
    "                                max_features=n_max_features,\n",
    "                                stop_words='english',\n",
    "                                max_df = 0.95,\n",
    "                                min_df = 2)\n",
    "    tf = tf_vectorizer.fit_transform(text)\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    return tf, tf_vectorizer, tf_feature_names\n",
    "    \n",
    "\n",
    "def LDA_analyze(tf_vector, n_topics):\n",
    "    lda = LatentDirichletAllocation(n_topics=n_topics,doc_topic_prior =1/(n_topics*10), max_iter=50,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                evaluate_every = 1,\n",
    "                                random_state=0)\n",
    "    lda.fit(tf_vector)\n",
    "    print(lda)\n",
    "    return lda\n",
    "\n",
    "def tf_idf(n_max_features, text):\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=0.95,\n",
    "                                       min_df=2,\n",
    "                                       max_features=n_max_features,\n",
    "                                       stop_words='english')\n",
    "    tfidf = tfidf_vectorizer.fit_transform(text)\n",
    "    tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "    return tfidf, tfidf_feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('\"urban vitality\".csv', names = 'abcdef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['e'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3773\n"
     ]
    }
   ],
   "source": [
    "data['e'] = data['c'].replace(r'http\\S+|http', '', regex=True).replace(r'www\\S+|WWW\\S+|www', '', regex=True)\n",
    "data['e'] = data['e'].str.lower().str.replace('skip to main content|skip to article|skip to content|main menu|page', '')\n",
    "data['e'] = data['e'].str.replace(r'[\\W_]+',' ')\n",
    "data['e'] = data['e'].str.replace(r'\\d+',' ')\n",
    "data['e'] = data['e'].str.replace(r'\\b(\\w)\\b', '')\n",
    "data['e'] = data['e'].replace(np.nan, '', regex=True)\n",
    "data['e'] = data['e'].apply(str)\n",
    "#print(data['e'])\n",
    "\n",
    "\n",
    "Len = len(data['e'])\n",
    "print(Len)\n",
    "#print(data.iloc[0:5,4:5])\n",
    "index_group = []\n",
    "for index, row in data.iterrows():\n",
    "    s =row[4]\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        index_group.append(index)\n",
    "    else:\n",
    "        continue\n",
    "    #print(data['e'][1])\n",
    "    #s =data.iloc[j]['e']\n",
    "    #isEnglish = s.encode(encoding='utf-8').decode('ascii')\n",
    "    #print(isEnglish)\n",
    "    #if not wordnet.synsets(data.iloc[j]['e']):#Comparing if word is non-English\n",
    "        #print(data.iloc[j]['e'])\n",
    "        #data.drop(j, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(index_group, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3491"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 73, 134, 597, 790, 792, 848, 904, 948, 957, 964, 1029, 1412, 1414, 1419, 1427, 1434, 1441, 1443, 1449, 1453, 1457, 1458, 1459, 1460, 1462, 1464, 1470, 1473, 1475, 1530, 1536, 1588, 1596, 1645, 1646, 1648, 1651, 1653, 1654, 1666, 1674, 1678, 1686, 1688, 1694, 1708, 1712, 1720, 1732, 1904, 1906, 1919, 1920, 1922, 1923, 1924, 1930, 1980, 1982, 1986, 1987, 1998, 1999, 2002, 2006, 2010, 2068, 2081, 2127, 2128, 2134, 2146, 2160, 2168, 2169, 2170, 2171, 2174, 2176, 2181, 2192, 2208, 2210, 2231, 2243, 2244, 2245, 2246, 2247, 2259, 2264, 2280, 2397, 2403, 2407, 2410, 2411, 2412, 2413, 2414, 2415, 2416, 2425, 2433, 2436, 2438, 2440, 2443, 2455, 2458, 2461, 2472, 2477, 2489, 2497, 2510, 2517, 2580, 2609, 2657, 2669, 2672, 2690, 2693, 2694, 2695, 2696, 2702, 2703, 2704, 2708, 2709, 2710, 2713, 2714, 2715, 2731, 2732, 2734, 2735, 2736, 2737, 2738, 2739, 2740, 2741, 2742, 2743, 2747, 2750, 2754, 2757, 2760, 2765, 2777, 2778, 2782, 2787, 2789, 2816, 2824, 2837, 2839, 2840, 2842, 2844, 2845, 2847, 2869, 2880, 2955, 2966, 2990, 3041, 3046, 3065, 3084, 3087, 3088, 3089, 3091, 3092, 3095, 3096, 3097, 3098, 3101, 3102, 3105, 3106, 3108, 3116, 3120, 3121, 3125, 3133, 3134, 3140, 3142, 3147, 3157, 3158, 3159, 3163, 3182, 3200, 3203, 3207, 3208, 3209, 3211, 3213, 3248, 3253, 3287, 3298, 3302, 3307, 3318, 3331, 3334, 3342, 3346, 3386, 3397, 3431, 3432, 3433, 3435, 3438, 3439, 3441, 3442, 3443, 3450, 3453, 3454, 3458, 3469, 3470, 3476, 3478, 3479, 3484, 3490, 3492, 3496, 3505, 3511, 3521, 3522, 3526, 3527, 3532, 3534, 3539, 3542, 3546, 3548, 3551, 3560, 3562, 3563, 3564, 3567, 3570, 3573, 3599, 3691, 3692, 3693, 3694, 3695, 3703, 3716, 3721, 3725, 3734, 3754, 3765, 3771]\n"
     ]
    }
   ],
   "source": [
    "print(index_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['e'].to_csv('after_clean7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_language = data['e']\n",
    "#text_all = data_language.tolist()\n",
    "#print(text_all[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data['e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' book  the renaissance  history of civilization in italy from     ad', ' html html towards  positive local government policy for residential rehabilitation', ' pdf pdf systems of urban growth ']\n"
     ]
    }
   ],
   "source": [
    "text_all = data_new.tolist()\n",
    "print(text_all[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:314: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDirichletAllocation(batch_size=128, doc_topic_prior=0.01,\n",
      "             evaluate_every=1, learning_decay=0.7,\n",
      "             learning_method='online', learning_offset=50.0,\n",
      "             max_doc_update_iter=100, max_iter=50, mean_change_tol=0.001,\n",
      "             n_components=10, n_jobs=None, n_topics=10, perp_tol=0.1,\n",
      "             random_state=0, topic_word_prior=None,\n",
      "             total_samples=1000000.0, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "n_max_features=3000\n",
    "n_topics = 10\n",
    "n_top_words = 10\n",
    "\n",
    "tf_vector, tf_vectorizer, tf_feature_names = tf_vctorize(n_max_features, text_all)\n",
    "lda = LDA_analyze(tf_vector, n_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: if you're in the IPython notebook, pyLDAvis.show() is not the best command\n",
      "      to use. Consider using pyLDAvis.display(), or pyLDAvis.enable_notebook().\n",
      "      See more information at http://pyLDAvis.github.io/quickstart.html .\n",
      "\n",
      "You must interrupt the kernel to end this command\n",
      "\n",
      "Serving to http://127.0.0.1:8889/    [Ctrl-C to exit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/Aug/2019 20:26:44] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Aug/2019 20:26:44] \"GET /LDAvis.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Aug/2019 20:26:44] \"GET /d3.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Aug/2019 20:26:45] \"GET /LDAvis.js HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "#tfidf, tfidf_feature_names = tf_idf(n_max_features, text_all)\n",
    "pyLDAvis.enable_notebook()\n",
    "lda_prepared = pyLDAvis.sklearn.prepare(lda, tf_vector, tf_vectorizer, R=20)\n",
    "pyLDAvis.show(lda_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreparedData(topic_coordinates=            Freq  cluster  topics         x         y\n",
      "topic                                                \n",
      "3      81.636049        1       1 -0.086795 -0.051051\n",
      "7       7.408662        1       2 -0.216661  0.092731\n",
      "1       4.003516        1       3  0.101290  0.186036\n",
      "0       2.105210        1       4 -0.044603 -0.074050\n",
      "2       1.452494        1       5  0.081438 -0.029212\n",
      "5       1.207190        1       6  0.031902 -0.028464\n",
      "8       0.598750        1       7  0.035711 -0.021016\n",
      "6       0.598153        1       8  0.034137 -0.025976\n",
      "4       0.561848        1       9  0.037109 -0.024882\n",
      "9       0.428127        1      10  0.026470 -0.024117, topic_info=     Category         Freq           Term        Total  loglift  logprob\n",
      "term                                                                    \n",
      "2855  Default  1337.000000          urban  1337.000000  20.0000  20.0000\n",
      "2921  Default   972.000000       vitality   972.000000  19.0000  19.0000\n",
      "1738  Default   108.000000            new   108.000000  18.0000  18.0000\n",
      "2357  Default   137.000000          rural   137.000000  17.0000  17.0000\n",
      "2861  Default    54.000000            use    54.000000  16.0000  16.0000\n",
      "647   Default    40.000000           data    40.000000  15.0000  15.0000\n",
      "1537  Default    37.000000          local    37.000000  14.0000  14.0000\n",
      "2609  Default    35.000000        studies    35.000000  13.0000  13.0000\n",
      "704   Default    30.000000        density    30.000000  12.0000  12.0000\n",
      "2500  Default    26.000000        society    26.000000  11.0000  11.0000\n",
      "1250  Default    58.000000         health    58.000000  10.0000  10.0000\n",
      "2848  Default    23.000000     university    23.000000   9.0000   9.0000\n",
      "2988  Default    41.000000          years    41.000000   8.0000   8.0000\n",
      "757   Default    91.000000    development    91.000000   7.0000   7.0000\n",
      "1702  Default    34.000000       national    34.000000   6.0000   6.0000\n",
      "2563  Default    35.000000          state    35.000000   5.0000   5.0000\n",
      "512   Default    38.000000     conditions    38.000000   4.0000   4.0000\n",
      "1487  Default    38.000000          large    38.000000   3.0000   3.0000\n",
      "1213  Default    29.000000          given    29.000000   2.0000   2.0000\n",
      "229   Default    30.000000          based    30.000000   1.0000   1.0000\n",
      "414    Topic1   146.628558           city   147.077775   0.1998  -4.7421\n",
      "142    Topic1    91.962519          areas    92.412255   0.1980  -5.2087\n",
      "870    Topic1    88.237760       economic    88.686342   0.1978  -5.2500\n",
      "2497   Topic1    81.310030         social    81.758925   0.1974  -5.3318\n",
      "728    Topic1    65.117506         design    65.566207   0.1960  -5.5539\n",
      "476    Topic1    60.228137      community    60.679556   0.1954  -5.6319\n",
      "1949   Topic1    51.823187       planning    52.271790   0.1943  -5.7822\n",
      "2284   Topic1    41.693620       research    42.142702   0.1922  -5.9997\n",
      "1484   Topic1    40.555777           land    41.004425   0.1919  -6.0274\n",
      "1325   Topic1    40.207931      important    40.656819   0.1918  -6.0360\n",
      "...       ...          ...            ...          ...      ...      ...\n",
      "2474   Topic9     0.518611            sir     4.713234   2.9747  -5.4079\n",
      "771    Topic9     0.526829    differences     9.983256   2.2399  -5.3921\n",
      "1587  Topic10     1.312843             md     2.622708   4.7615  -4.2072\n",
      "2342  Topic10     0.408977          roads     1.044472   4.5159  -5.3735\n",
      "1166  Topic10     0.229992           frcp     1.012668   3.9712  -5.9492\n",
      "297   Topic10     0.529852        british     2.387779   3.9480  -5.1146\n",
      "2396  Topic10     0.229989         season     1.093674   3.8942  -5.9492\n",
      "1601  Topic10     0.600174        meeting     3.012068   3.8403  -4.9900\n",
      "2569  Topic10     0.229985    statistical     1.260468   3.7523  -5.9492\n",
      "785   Topic10     0.236723     diminution     1.442947   3.6460  -5.9203\n",
      "288   Topic10     0.432499         branch     2.738984   3.6077  -5.3176\n",
      "117   Topic10     0.600198         annual     4.055347   3.5430  -4.9899\n",
      "209   Topic10     0.228534  automatically     1.564897   3.5296  -5.9555\n",
      "2636  Topic10     0.229993   sufficiently     1.587282   3.5218  -5.9491\n",
      "1675  Topic10     0.233575  mortification     1.616826   3.5188  -5.9337\n",
      "861   Topic10     0.229672            ear     1.601812   3.5113  -5.9505\n",
      "1362  Topic10     0.228354   individually     1.619400   3.4946  -5.9563\n",
      "1843  Topic10     0.233203        orleans     1.674271   3.4823  -5.9353\n",
      "1859  Topic10     0.438445           pain     3.682719   3.3253  -5.3040\n",
      "2797  Topic10     0.642101      treatment     5.590129   3.2895  -4.9225\n",
      "1801  Topic10     0.229992        officer     2.096768   3.2434  -5.9492\n",
      "524   Topic10     0.435804       congress     4.542966   3.1094  -5.3100\n",
      "40    Topic10     0.486260        address    10.823506   2.3508  -5.2005\n",
      "1748  Topic10     0.431182            non    12.776574   2.0647  -5.3207\n",
      "1597  Topic10     0.360753        medical     9.370280   2.1964  -5.4990\n",
      "1487  Topic10     0.230048          large    38.035245   0.3455  -5.9489\n",
      "1537  Topic10     0.230011          local    37.366821   0.3631  -5.9491\n",
      "1465  Topic10     0.230005           july     4.853419   2.4042  -5.9491\n",
      "2046  Topic10     0.229996      principal     3.853771   2.6348  -5.9491\n",
      "1685  Topic10     0.229994             mr     9.136991   1.7715  -5.9491\n",
      "\n",
      "[347 rows x 6 columns], token_table=      Topic      Freq            Term\n",
      "term                                 \n",
      "24        1  0.849055            acid\n",
      "24        9  0.283018            acid\n",
      "25        5  0.728363             act\n",
      "30        1  0.853226        activity\n",
      "30        3  0.089813        activity\n",
      "40        1  0.923915         address\n",
      "45        3  0.338309  administrative\n",
      "45        4  0.676619  administrative\n",
      "51        3  0.659080        advanced\n",
      "63        4  0.829216          africa\n",
      "67        1  0.572279             age\n",
      "67        2  0.238449             age\n",
      "67        3  0.143070             age\n",
      "67        7  0.047690             age\n",
      "71        1  0.683796            ages\n",
      "71        9  0.227932            ages\n",
      "73        5  0.515383           agree\n",
      "77        4  0.560284           ahmed\n",
      "82        1  0.537858             air\n",
      "82        2  0.089643             air\n",
      "82        3  0.358572             air\n",
      "91        7  0.929326         allowed\n",
      "101       1  0.979946        american\n",
      "117       1  0.739764          annual\n",
      "117      10  0.246588          annual\n",
      "123       3  0.886452          aphids\n",
      "142       1  0.995539           areas\n",
      "150       2  0.998981             art\n",
      "151       1  0.743745         article\n",
      "151       6  0.247915         article\n",
      "...     ...       ...             ...\n",
      "2901      6  0.166824            view\n",
      "2906      8  0.730386        vigorous\n",
      "2914      6  0.567922       virulence\n",
      "2921      1  0.914604        vitality\n",
      "2921      2  0.069958        vitality\n",
      "2921      3  0.008230        vitality\n",
      "2921      4  0.006173        vitality\n",
      "2922      4  0.563919       vitiation\n",
      "2932      6  0.836955     walkability\n",
      "2938      1  0.531161      washington\n",
      "2938      3  0.531161      washington\n",
      "2940      1  0.120318           water\n",
      "2940      2  0.120318           water\n",
      "2940      3  0.481271           water\n",
      "2940      4  0.060159           water\n",
      "2940      5  0.180477           water\n",
      "2941      6  0.803521      waterfront\n",
      "2942      1  0.860422             way\n",
      "2942      3  0.061459             way\n",
      "2942      8  0.061459             way\n",
      "2949      5  0.515413        websites\n",
      "2974      1  0.980028            work\n",
      "2987      1  0.462384            year\n",
      "2987      2  0.462384            year\n",
      "2988      1  0.649288           years\n",
      "2988      2  0.312620           years\n",
      "2988      4  0.024048           years\n",
      "2990      4  0.982540            york\n",
      "2994      3  0.952223              yr\n",
      "2996      5  0.633201        zhejiang\n",
      "\n",
      "[477 rows x 3 columns], R=20, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 8, 2, 1, 3, 6, 9, 7, 5, 10])\n"
     ]
    }
   ],
   "source": [
    "print(lda_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "0.01\n",
      "{'xlab': 'PC1', 'ylab': 'PC2'}\n",
      "[10, 6, 1, 8, 4, 9, 7, 2, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "N=10\n",
    "for i in lda_prepared[3:]:\n",
    "    #i.shape()\n",
    "    print(i)\n",
    "    N+=1\n",
    "    #i.to_csv(\"output\"+ str(N) +'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "[279 126 122 258  73 257 174 182  36]\n",
      "Topic #1:\n",
      "[ 30 277 105 210 193 149  52 201 197]\n",
      "Topic #2:\n",
      "[169  76  68  13  52  12 194  16  17]\n",
      "Topic #3:\n",
      "[ 39  80 283  57 205  59 197 111 179]\n",
      "Topic #4:\n",
      "[216 187 262 209  55  19  42 133 129]\n",
      "Topic #5:\n",
      "[279 126 122 258  73 257 174 182  36]\n",
      "Topic #6:\n",
      "[ 30 277 105 210 193 149  52 201 197]\n",
      "Topic #7:\n",
      "[ 57 133 137  42 274  35 197 179  24]\n",
      "Topic #8:\n",
      "[237 163  36 122 241 124 257  10 184]\n",
      "Topic #9:\n",
      "[135  19  24  66 297 163 279  55  58]\n"
     ]
    }
   ],
   "source": [
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(\"Topic #%d:\" % topic_idx)\n",
    "    #print(topic)\n",
    "    print(topic.argsort()[-10:-1])\n",
    "    #print(topic.argsort()[:-n_top_words - 1:-1])\n",
    "    #print(tf_feature_names)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '10', '1000', '1080', '1085', '10th', '11', '1100', '1145', '11th', '12', '12th', '14th', '15', '15th', '17th', '19th', '1st', '20', '20th', '30', '3pm', '900', 'able', 'absolute', 'absolutely', 'access', 'accessible', 'according', 'acoustics', 'action', 'activities', 'actually', 'addition', 'adjacent', 'admire', 'admission', 'adults', 'afternoon', 'age', 'ages', 'ago', 'air', 'alike', 'alive', 'allow', 'allowed', 'altar', 'alter', 'amazing', 'amazingly', 'ambience', 'ancient', 'anytime', 'app', 'appreciate', 'april', 'arch', 'architectural', 'architecture', 'area', 'areas', 'array', 'arrived', 'art', 'artifacts', 'ask', 'asked', 'aspects', 'assembled', 'astrological', 'astronomic', 'astronomical', 'atmosphere', 'attached', 'attended', 'attraction', 'attractions', 'attractive', 'august', 'aula', 'austere', 'authentic', 'autumn', 'available', 'away', 'awe', 'awesome', 'baby', 'bar', 'basement', 'basic', 'basis', 'bathrooms', 'beatiful', 'beautiful', 'beautifull', 'beautifully', 'beauty', 'beds', 'believe', 'belonged', 'bench', 'benches', 'best', 'better', 'big', 'bigger', 'biggest', 'bird', 'birds', 'bit', 'blocks', 'bloom', 'blooming', 'blooms', 'boasts', 'book', 'boring', 'born', 'botan', 'botanic', 'botanical', 'break', 'bright', 'bring', 'brought', 'build', 'building', 'buildings', 'built', 'bushes', 'business', 'busy', 'buy', 'caf', 'cafe', 'cafes', 'calculate', 'calendar', 'called', 'calm', 'calming', 'came', 'campus', 'candle', 'candles', 'care', 'cared', 'carved', 'carvings', 'catacombs', 'catch', 'cathedral', 'cathedrals', 'catholic', 'caught', 'celebrate', 'celebrating', 'celebrations', 'cellar', 'center', 'central', 'centre', 'centuries', 'century', 'ceramics', 'certainly', 'chance', 'characters', 'charge', 'charming', 'check', 'child', 'children', 'chimes', 'choir', 'chose', 'christian', 'christianity', 'christmas', 'church', 'churches', 'city', 'classes', 'clean', 'clear', 'climate', 'climates', 'climbing', 'clock', 'close', 'closed', 'closes', 'cobbled', 'coffee', 'cold', 'collected', 'collection', 'color', 'colorful', 'colours', 'come', 'comes', 'compared', 'complete', 'concert', 'concerts', 'conservatory', 'constructed', 'contain', 'contains', 'cool', 'copenhagen', 'corner', 'cost', 'cosy', 'cottages', 'couldn', 'countryside', 'couple', 'couples', 'course', 'creepy', 'crowd', 'crowded', 'crypt', 'crypts', 'cultural', 'culture', 'cup', 'curious', 'cute', 'daily', 'danish', 'dark', 'date', 'dates', 'dating', 'day', 'days', 'decided', 'decorated', 'decoration', 'decorations', 'definitely', 'delightful', 'denmark', 'design', 'designed', 'details', 'detour', 'did', 'didn', 'different', 'disappointed', 'discover', 'display', 'displayed', 'displays', 'distance', 'diverse', 'does', 'doesn', 'doing', 'dominates', 'dominating', 'domkyrkan', 'don', 'door', 'doors', 'downstairs', 'downtown', 'drink', 'drinking', 'drinks', 'ducks', 'dwellings', 'early', 'earth', 'easily', 'east', 'easy', 'eat', 'eating', 'elements', 'end', 'ended', 'english', 'enjoy', 'enjoyable', 'enjoyed', 'enjoying', 'enormous', 'enter', 'entering', 'entire', 'entrance', 'entry', 'environment', 'equipment', 'era', 'especially', 'europe', 'european', 'evening', 'event', 'events', 'everybody', 'example', 'excellent', 'exception', 'exercise', 'exhibit', 'exhibition', 'exhibitions', 'exhibits', 'exotic', 'expect', 'expected', 'expensive', 'experience', 'experiencing', 'explanation', 'explanations', 'explore', 'exploring', 'extensive', 'exterior', 'externally', 'extremely', 'eyes', 'fabulous', 'facing', 'fact', 'facts', 'fairly', 'fall', 'families', 'family', 'famous', 'fantastic', 'far', 'fascinating', 'favorite', 'features', 'fee', 'feed', 'feel', 'feeling', 'feels', 'felt', 'festival', 'figure', 'figures', 'fika', 'filled', 'final', 'fine', 'finest', 'finn', 'floor', 'flower', 'flowers', 'focal', 'follow', 'food', 'forest', 'forget', 'form', 'formal', 'forum', 'founded', 'fountain', 'free', 'friendly', 'friends', 'fully', 'fun', 'furnished', 'furniture', 'gallery', 'garden', 'gardeners', 'gardens', 'gem', 'getting', 'giant', 'given', 'gives', 'giving', 'glass', 'glasshouse', 'glasshouses', 'goes', 'going', 'gone', 'good', 'gorgeous', 'got', 'gothic', 'grand', 'grandchildren', 'grass', 'graves', 'graveyard', 'great', 'green', 'greenery', 'greenhouse', 'greenhouses', 'grounds', 'group', 'groups', 'grown', 'guide', 'guided', 'gym', 'half', 'hall', 'hand', 'hang', 'hanging', 'happen', 'happened', 'hard', 'having', 'head', 'hear', 'heart', 'help', 'helps', 'high', 'highlight', 'highlights', 'highly', 'historic', 'historical', 'historically', 'history', 'holding', 'home', 'homes', 'horologium', 'hosts', 'hot', 'hothouses', 'hour', 'hours', 'house', 'houses', 'huge', 'husband', 'idea', 'ideal', 'important', 'imposing', 'impressed', 'impressive', 'included', 'includes', 'including', 'incredible', 'indoor', 'indoors', 'info', 'information', 'informative', 'inside', 'insight', 'inspiring', 'interactive', 'interested', 'interesting', 'interior', 'intriguing', 'introduction', 'inviting', 'isn', 'items', 'joined', 'journey', 'joy', 'joyful', 'june', 'just', 'kept', 'kids', 'kind', 'kinds', 'knights', 'know', 'kulturen', 'lady', 'laid', 'lake', 'landmark', 'large', 'late', 'lawns', 'leaflet', 'learn', 'learning', 'leave', 'left', 'legend', 'let', 'level', 'life', 'light', 'like', 'liked', 'listen', 'little', 'live', 'lived', 'living', 'll', 'loads', 'local', 'locals', 'located', 'location', 'long', 'look', 'looked', 'looking', 'looks', 'lot', 'lots', 'love', 'loved', 'lovely', 'lower', 'lucky', 'lunch', 'lunches', 'lund', 'lundag', 'lundense', 'lunds', 'lush', 'lutheran', 'magical', 'magnificent', 'main', 'maintained', 'majestic', 'major', 'make', 'makes', 'malm', 'malmo', 'managed', 'mary', 'mass', 'massive', 'masterpiece', 'matter', 'maybe', 'medieval', 'meet', 'meeting', 'men', 'meter', 'mid', 'midday', 'middle', 'mighty', 'mind', 'minutes', 'miss', 'missed', 'mixture', 'model', 'modern', 'moment', 'mon', 'money', 'months', 'monument', 'moon', 'morning', 'mornings', 'moved', 'moving', 'museum', 'museums', 'music', 'musical', 'natural', 'nature', 'ne', 'near', 'nearby', 'need', 'new', 'nice', 'night', 'noon', 'nordic', 'north', 'northern', 'note', 'notice', 'number', 'oasis', 'object', 'objects', 'october', 'offer', 'offers', 'office', 'old', 'older', 'oldest', 'ones', 'open', 'orchids', 'organ', 'organized', 'original', 'ornate', 'outdoor', 'outdoors', 'outside', 'outstanding', 'overall', 'painted', 'park', 'particular', 'particularly', 'partly', 'parts', 'party', 'passed', 'passing', 'past', 'pastor', 'paths', 'pay', 'peace', 'peaceful', 'pedestrian', 'people', 'perfect', 'perfectly', 'period', 'periods', 'permanent', 'person', 'photograph', 'photos', 'pick', 'picknick', 'picnic', 'picnics', 'picture', 'piece', 'pillar', 'pillars', 'place', 'places', 'plain', 'plant', 'plants', 'play', 'playground', 'playing', 'plays', 'pleasant', 'pleasure', 'plenty', 'plus', 'pm', 'point', 'pond', 'poor', 'pop', 'pope', 'popular', 'possible', 'power', 'prague', 'present', 'presentation', 'preserved', 'pretty', 'price', 'prices', 'probably', 'procession', 'provided', 'provides', 'public', 'purposes', 'quail', 'quails', 'quick', 'quiet', 'quirky', 'quite', 'rain', 'rainy', 'range', 'rare', 'rd', 'read', 'reading', 'real', 'really', 'reason', 'rebuilt', 'recently', 'recommend', 'recommended', 'region', 'regular', 'relatively', 'relax', 'relaxed', 'relaxing', 'religious', 'remains', 'remember', 'represented', 'research', 'rest', 'restaurant', 'restaurants', 'restored', 'rich', 'right', 'roam', 'rock', 'role', 'roman', 'romanesque', 'roof', 'room', 'rooms', 'round', 'run', 'running', 'sadly', 'said', 'sandstone', 'sat', 'saturday', 'saw', 'say', 'says', 'scandinavia', 'scandinavian', 'scania', 'scenery', 'school', 'season', 'seat', 'seating', 'seats', 'second', 'sections', 'seeing', 'seen', 'selection', 'sense', 'september', 'serenity', 'served', 'serves', 'service', 'services', 'set', 'setting', 'shop', 'shops', 'short', 'shouldn', 'showing', 'shows', 'shrubs', 'sight', 'sights', 'signs', 'silence', 'similar', 'simple', 'simply', 'singing', 'sit', 'site', 'sites', 'sitting', 'situated', 'size', 'sk', 'skane', 'skansen', 'slightly', 'small', 'smaller', 'smells', 'snacks', 'solo', 'somewhat', 'son', 'sorts', 'sound', 'south', 'southern', 'space', 'spacious', 'special', 'specially', 'species', 'spectacular', 'spend', 'spending', 'spent', 'spiritual', 'spot', 'spread', 'spring', 'square', 'stadsparken', 'staff', 'stalls', 'standing', 'stands', 'start', 'started', 'starting', 'starts', 'station', 'statue', 'stay', 'stayed', 'staying', 'stocked', 'stockholm', 'stone', 'stones', 'stop', 'stopped', 'stops', 'stories', 'story', 'strange', 'street', 'streets', 'strike', 'striking', 'stroll', 'strolling', 'structure', 'student', 'students', 'study', 'stuff', 'stunning', 'style', 'summer', 'sun', 'sunday', 'sunny', 'super', 'sure', 'surprised', 'surrounded', 'surrounding', 'surroundings', 'sweden', 'swedes', 'swedish', 'sweet', 'taken', 'taking', 'tale', 'talk', 'tea', 'tell', 'temperature', 'temporary', 'text', 'thing', 'things', 'think', 'thought', 'thousand', 'thousands', 'till', 'time', 'times', 'timing', 'tiny', 'today', 'told', 'tombs', 'took', 'totally', 'touching', 'tour', 'tourist', 'tourists', 'tours', 'towers', 'town', 'traditional', 'train', 'tranquility', 'travel', 'traveling', 'treat', 'tree', 'trees', 'trip', 'tropical', 'true', 'truly', 'try', 'trying', 'twice', 'type', 'types', 'typical', 'underground', 'understand', 'understanding', 'unexpected', 'unfortunately', 'unique', 'university', 'unlike', 'unusual', 'use', 'used', 'usually', 'varieties', 'variety', 'various', 've', 'view', 'vikings', 'village', 'visit', 'visited', 'visiting', 'visitor', 'visitors', 'visually', 'wait', 'walk', 'walked', 'walking', 'wall', 'wander', 'wandering', 'want', 'warm', 'warmth', 'wasn', 'watch', 'watching', 'way', 'ways', 'weather', 'week', 'welcome', 'welcoming', 'went', 'white', 'wich', 'wide', 'wife', 'wild', 'windows', 'wine', 'winter', 'wish', 'witness', 'woman', 'wonder', 'wonderful', 'wood', 'wooden', 'word', 'work', 'working', 'works', 'world', 'worth', 'wow', 'year', 'years', 'yes', 'young', 'youngsters', 'zones']\n"
     ]
    }
   ],
   "source": [
    "print(tf_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "lund buildings old museum sweden different swedish history houses visit time place interesting kulturen day trip really cathedral people outside went house exhibits times life culture small visited lived exhibitions\n",
      "Topic #1:\n",
      "kids place playground children liked peaceful really fun various bit enjoyed exhibits denmark great area going especially love caf outdoor old set fantastic perfect took season beauty summer amazing way\n",
      "Topic #2:\n",
      "exhibition art areas people april children architectural dating early medieval religious noon different lund day crypt visited huge beautiful visit nice center church old fascinating cathedral interesting museum small century\n",
      "Topic #3:\n",
      "park nice good place close pond city walk enjoy cafe recommended people lund children little birds relax students coffee located miss day town outdoor play weather stadsparken look easily sunny\n",
      "Topic #4:\n",
      "clock impressive inside cathedral astronomical church read time outside religious giant town basement visit walking want small early recommend learn sun large quite little took loved built main attraction highly\n",
      "Topic #5:\n",
      "lund buildings old museum sweden different swedish history houses visit time place interesting kulturen day trip really cathedral people outside went house exhibits times life culture small visited lived exhibitions\n",
      "Topic #6:\n",
      "kids place playground children liked peaceful really fun various bit enjoyed exhibits denmark great area going especially love caf outdoor old set fantastic perfect took season beauty summer amazing way\n",
      "Topic #7:\n",
      "lund beautiful nice place building university cathedral just inside city year day recommend quiet famous spring walk town walking main great look center want garden students area like time huge\n",
      "Topic #8:\n",
      "museum open air sweden hours spent history buildings lund southern people houses enjoyed great building kulturen city entrance exhibitions culture really way showing walking fantastic interested nice swedish friendly visiting\n",
      "Topic #9:\n",
      "cathedral clock church visit lund worth crypt beautiful astronomical interesting inside history old impressive time giant miss amazing don free tour architecture visiting finn english building century town sweden visited\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-30 - 1:-1]]))\n",
    "    print()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
